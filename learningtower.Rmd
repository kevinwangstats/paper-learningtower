---
title: "learningtower: an R package for Exploring Standardised Test Scores Across the Globe"
date: "`r Sys.Date()`"
abstract: >
  Reproducibility is a key aspect of data analysis. Furthermore, it adds context to scientific results, increasing public confidence and laying the groundwork for future study. The Programme for International Student Assessment (PISA) is a well-known open data set that is freely available. This data has the ability to provide meaningful results and insights that can help with various decisions in the fields of education and research. This experiment has a direct influence on society for the benefit of people's lives. In this article, we introduce the `learningtower` package, which provides a user-friendly easy accessibility to a subset of variables from PISA data gathered by the Organization for Economic Cooperation and Development (OECD) from 2000 to 2022. This dataset is well suited for data exploration, visualisation and various analytical and statistical analysis. In addition, we present a few example analysis utilizing this dataset addressing some research questions regarding the gender gap noticed in these students, the effect of different socioeconomic factors on the students' performance, and we go further to study Australia's PISA scores.
draft: true
author: 
  # see ?rjournal_article for more information
  - name: Priya Ravindra Dingorkar
    url: https://www.linkedin.com/in/priya-dingorkar/
    email: priyadingorkar@gmail.com
    orcid: 0009-0007-2655-1475
    affiliation: Monash University
    address:
    - Department of Econometrics and Business Statistics
    - Clayton, Australia
  - name: Dianne Cook
    affiliation: Monash University
    address:
    - Department of Econometrics and Business Statistics
    - Clayton, Australia
    url: http://dicook.org/
    email: dicook@monash.edu
    orcid: 0000-0002-3813-7155
  - name: Kevin Y.X. Wang
    affiliation: University of Sydney
    address:
    - School of Mathematics and Statistics 
    - Sydney, Australia
    url: https://kevinwang09.github.io/
    email: kevinwangstats@gmail.com 
    orcid: 0000-0003-2615-6102
type: package
# csl: "rjournal.csl"
creative_commons: CC BY
output: 
  rjtools::rjournal_article
header-includes:
    \usepackage{float}
    \floatplacement{figure}{H}
bibliography: learningtower.bib
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE)
```

```{r loadlibraries}
library(rjtools)
library(learningtower)
library(tidyverse)
library(viridis)
library(patchwork)
library(plotly)
library(ggbeeswarm)
library(gganimate)
library(ggrepel)
library(colorspace)
library(ggthemes)
library(rnaturalearth)
library(sf)
# Note: rnaturalearth provides a map that is 1/10th size of 
# of the map provided by ggplot2::map_data()
```

# Introduction

The Organization for Economic Cooperation and Development [OECD](https://www.oecd.org/about/) is a global organization that aims to create better policies for better lives. Its mission is to create policies that promote prosperity, equality, opportunity, and well-being for all. [@oecd] [PISA](https://www.oecd.org/pisa/) is one of OECD's Programme for International Student Assessment. PISA assesses 15-year-old students' potential to apply their knowledge and abilities in reading, mathematics, and science to real-world challenges. OECD launched this in 1997, it was initially administered in 2000, and it currently includes over [80 nations](https://www.oecd.org/pisa/aboutpisa/pisa-participants.htm). [@pisa] The PISA study, conducted every three years, provides comparative statistics on 15-year-olds' performance in reading, math, and science. This paper describes how to utilize the `learningtower` package, which offers OECD PISA datasets from 2000 to 2022 in an easy-to-use format. This dataset comprises information on their test results and other socioeconomic factors, as well as information on their schools, infrastructure and the countries participating in the program.

# What is PISA?

PISA assesses the extent to which children approaching the end of compulsory school have learned some of the information and abilities required for full participation in modern society, notably in math, reading, and science. The examination focuses on reading, mathematics, science, and problem solving. It also assesses students capacity to replicate information and extrapolate from what they have learned and apply that knowledge in unexpected circumstances, both inside and outside of school. This approach reflects the fact that individuals are rewarded in modern economies not for what they know, but for what they can accomplish with what they know.

This evaluation which is carried out every three years, assists in identifying students' development of knowledge and skills throughout the world, which can provide actionable insights and therefore assist education policymakers. PISA is well known for its distinctive testing characteristics, which include policy orientation, an innovative notion of literacy, relevance to lifelong learning, regularity, and breadth of coverage. PISA is now used as an assessment tool in many regions around the world. In addition to OECD member countries, the survey has been or is being conducted in East, South and Southeast Asia, Central, Mediterranean and Eastern Europe, and Central Asia, The Middle East, Central and South America and Africa. [@pisabook]

For each year of the PISA study, one domain subject is thoroughly examined. In 2022, for example, reading was assessed alongside mathematics and science as minor areas of assessment. The 2012 survey concentrates on mathematics, with reading, science, and problem solving serving as minor evaluation topics. PISA targets a certain age group of students in order to properly compare their performance worldwide. PISA students are aged between 15 years 3 months and 16 years 2 months at the time of the assessment, and have completed at least 6 years of formal schooling. They can enroll in any sort of institution, participate in full-time or part-time education, academic or vocational programs, and attend public, private, or international schools inside the country. Using this age across nations and throughout time allows PISA to compare the knowledge and abilities of people born in the same year who are still in school at the age of 15, irrespective of their diverse schooling. [@pisabook]

The PISA test is primarily computer-based and lasts around 2 hours. The examination comprises both multiple choice and free entry questions. Some countries that were not ready for computer-based delivery carried out the testing on paper. Each student may have a unique set of questions. An example of the test may be seen [here](https://www.oecd.org/pisa/test/). PISA assessment areas seek to measure the following aspects of students' literacy in math, reading, and science. The goal of mathematical literacy is to assess students ability to grasp and interpret mathematics in a variety of settings. Reading literacy assesses students' capacity to absorb, apply, analyze, and reflect on texts in order to attain required goals and participate in society. Science literacy is described as the ability to engage with science-related issues and scientific concepts as a reflective citizen. [@test]

PISA data is publicly accessible for [download](https://www.oecd.org/pisa/data/). Furthermore, reading the [data documentation](https://www.oecd.org/pisa/data/pisa2018technicalreport/Ch.09-Scaling-PISA-Data.pdf) reveals that the disclosed PISA scores are generated using a sophisticated linear model applied to the data. For each student, several values are simulated. [@scaling] This is known as synthetic data, and it is a popular technique to ensuring data privacy. The data can still be deemed accurate within the mean, variance, and stratum used in the original data's modelling. In addition, the PISA website provides the data in SPSS and SAS format, which can limit accessibility due to the commercial nature of these software. Furthermore, all questions are assigned with unique IDs within each year of the PISA study, but do not always agree across the different years. This data has now been curated and simplified into a single R package called `learningtower`, which contains all of the PISA scores from the years 2000 to 2022.

# Data compilation

Each developer at the ROpenSci OzUnconf was assigned to curate a specific year of the PISA study. Data on the participating students and schools were first downloaded from the PISA website, in either SPSS or SAS format. The data were read into an R environment with the exception of the year 2000 and 2003. Due to formatting issues, the data for these two particular years were first read using SPSS and then exported into compatible `.sav` files. After some data cleaning and wrangling with the appropriate script, the variables of interest were re-categorised and saved as RDS files. One major challenge faced by the developers was to ensure the consistency of variables over the years. For example, a student's mother's highest level of education was never recorded in 2000, but it was categorised as "ST11R01" between 2003 and 2012 and "ST005Q01TA" between 2015 and 2022. Such a problem was tackled manually by curating these values as an integer variable named "mother_educ" in the output data.

# What is `learningtower`?

The R package ['learningtower'](https://cran.r-project.org/web/packages/learningtower/index.html) [@learningtower] provides quick access to a variety of variables in the OECD PISA data collected over three-year periods from 2000 to 2022. This dataset includes information on the PISA test scores in mathematics, reading, and science. Furthermore, these datasets include information on other socioeconomic aspects, as well as information on their school and its facilities, as well as the nations participating in the program.

The motivation for developing the `learningtower` package was sparked by the announcement of the PISA 2018 results, which caused a collective wringing of hands in the Australian press, with headlines such as ["Vital Signs: Australia's slipping student scores will lead to greater income inequality"](https://theconversation.com/vital-signs-australias-slipping-student-scores-will-lead-to-greater-income-inequality-128301) and ["In China, Nicholas studied math 20 hours a week. In Australia, it's three"](https://www.smh.com.au/education/in-china-nicholas-studied-maths-20-hours-a-week-in-australia-it-s-three-20191203-p53ggv.html). That's when several academics from Australia, New Zealand, and Indonesia decided to make things easier by providing easy access to PISA scores as part of the [ROpenSci OzUnconf](https://ozunconf19.ropensci.org/), which was held in Sydney from December 11 to 13, 2019. The data from this survey, as well as all other surveys performed since the initial collection in 2000, is freely accessible to the public. However, downloading and curating data across multiple years of the PISA study could be a time consuming task. As a result, we have made a more convenient subset of the data freely available in a new R package called \CRANpkg{learningtower}, along with sample code for analysis.

The \CRANpkg{learningtower} package primarily comprised of three datasets: `student`, `school`, and `countrycode.` The `student` dataset includes results from triennial testing of 15-year-old students throughout the world. This dataset also includes information about their parents' education, family wealth, gender, and presence of computers, internet, vehicles, books, rooms, desks, and other comparable factors. Due to the size limitation on CRAN packages, only a subset of the student data can be made available in the downloaded package. These subsets of the student data, known as the `student_subset_yyyy` (`yyyy` being the specific year of the study) allow uses to quickly load, visualise the trends in the full data. The full student dataset can be downloaded using the `load_student()` function included in this [package.](https://kevinwang09.github.io/learningtower/) The `school` dataset includes school weight as well as other information such as school funding distribution, whether the school is private or public, enrollment of boys and girls, school size, and similar other characteristics of interest of different schools these 15-year-olds attend around the world. The `countrycode` dataset includes a mapping of a country/region's ISO code to its full name.

The \CRANpkg{learningtower} developers are committed to providing R users with data to analyse PISA results every three years. Our package's future enhancements include updating the package every time additional PISA scores are announced. Note that, in order to account for post COVID-19 problems, OECD member nations and associates decided to postpone the PISA 2021 evaluation to 2022 and the PISA 2024 assessment to 2025.

# Example analysis

In this section we will illustrate how the \CRANpkg{learningtower} package can be utilized to answer some research questions by applying various methodologies and statistical computations on the \CRANpkg{learningtower} datasets.

We will utilize the 2018 PISA data and scores for illustrative purposes throughout the example analysis section. During the post-development phase, the \CRANpkg{learningtower} developers collectively decided to answer a few intriguing questions on the PISA data and see if we could identify any interesting trends or insights utilizing this dataset. Some of these questions include if there is any significant gender difference between girls and boys and explore their performance in the areas of mathematics, reading, and science. Furthermore, we will inspect the various socioeconomic characteristics reflected in the student data and investigate if they have any substantial impact on the scores of these 15-year-olds. We will delve into Australia's score history and study the temporal trends to uncover some noteworthy trends that Australia has observed as a result of its participation in the PISA experiment.

# Gender analysis

Gender gaps have always been a topic of interest among researchers, and when it comes to PISA data and scores of 15-year-old students around the world, uncovering patterns based on their gender would help gain meaningful insights in the field of education for various education policymakers around the world. Based on the 2018 PISA results, let us see if there is a major gender disparity between girls and boys throughout the world in mathematics, reading, and science. To begin, we will create a 'data.frame' that stores the weighted average math score for each nation as well as the various regions of the countries grouped by country and gender, in order to create this `data.frame` and represent data in the tidy format we use the \CRANpkg{tidyverse} [@tidyverse] and \CRANpkg{dplyr} [@dplyr] R packages. [Survey weights](https://www.oecd.org/pisa/data/2015-technical-report/PISA-2015-Technical-Report-Chapter-8-Survey-Weighting.pdf) are critical and must be used in the analysis to guarantee that each sampled student accurately represents the total number of pupils in the PISA population. In addition, we compute the gender difference between the two averages. To demonstrate the variability in the mean estimate, we use bootstrap sampling with replacement using the `map_dfr` function on the data and compute the same mean difference estimate. For each country, the empirical 90 percent confidence intervals are presented. The same process is used for reading and science test scores.

```{r plotgendergapmath}
# Load data pre-computed by previous chunks
load("data/math_diff_conf_intervals.rda")

# Plot math
math_plot <- ggplot(math_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#A962B6",  #"#3288bd",
                 "nodiff"="#969696",
                 "girls"="#378E38")) + #"#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "math"
  ) +
  theme_bw() +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "girls") +
  annotate("text", x = -50, y = 1, label = "boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```

```{r plotgendergapread}
# Load data pre-computed by previous chunks
load("data/read_diff_conf_intervals.rda")

read_plot <- ggplot(read_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#A962B6",  #"#3288bd",
                 "nodiff"="#969696",
                 "girls"="#378E38")) + #"#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "reading"
  ) +
  theme_bw() +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "girls") +
  annotate("text", x = -50, y = 1, label = "boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```

```{r plotgendergapsci}
# Load data pre-computed by previous chunks
load("data/sci_diff_conf_intervals.rda")

sci_plot <- ggplot(sci_diff_conf_intervals,
                    aes(diff, country_name,
                        col = score_class)) +
  scale_colour_manual("",
      values = c("boys"="#A962B6",  #"#3288bd",
                 "nodiff"="#969696",
                 "girls"="#378E38")) + #"#f46d43")) +
  geom_point() +
  geom_errorbar(aes(xmin = lower, xmax = upper), width=0) +
  geom_vline(xintercept = 0, color = "#969696") +
  labs(y = "",
  x = "",
  title = "science"
  ) +
  theme_bw() +
  theme(legend.position="none") +
  annotate("text", x = 50, y = 1, label = "girls") +
  annotate("text", x = -50, y = 1, label = "boys") +
  scale_x_continuous(limits = c(-70, 70),
                     breaks = seq(-60, 60, 20),
                     labels = abs(seq(-60, 60, 20)))
```

```{r score-differences, fig.cap ="The gender gap difference in 15-year-olds' in math, reading, and science results in 2018, with bootstrapped 95% errors. The scores to the right of the grey line (green) represent the performances of the girls, while the scores to the left of the grey line (purple) represent the performances of the boys. The gender gap is not universal in math and science, but on average in reading, girls from all countries outperformed boys.", fig.width=11, fig.height=11, fig.pos = "H", out.width="100%", layout="l-body", fig.alt="A comparative dot plot visualizing gender differences in math, reading, and science scores across various countries. The x-axis represents the gender gap, with boys on the left and girls on the right. Each country is listed on the y-axis, with color-coded points indicating the degree of gender difference. In math, boys tend to outperform girls in most countries, as shown by the purple dots to the left. In reading, girls outperform boys, indicated by the green dots on the right. Science scores exhibit a more balanced distribution, with some variation by country."}

math_plot + read_plot + sci_plot
```

Figure \@ref(fig:score-differences) illustrates the global disparities in mean math, reading, and science outcomes, before we get to the plot conclusion, let's have a look at the variables that have been plotted. The grey line here indicates a reference point, and all of the scores to the right of the grey line show the scores of girls in math, reading, and science. Similarly, the scores on the left side of this grey line indicate the scores of boys in the three disciplines. Based on Figure \@ref(fig:score-differences), because most math estimates and confidence intervals lie to the left of the grey line, we may conclude that most boys outperformed girls in math. In nations such as Morocco, Netherlands, Slovenia, Kazakhstan, Poland, Bulgaria, and Greece, there is almost no gender difference in average math scores. When we look at the reading scores, we notice a remarkable trend in that all girls outpaced boys in reading in all countries in 2018. The highest reading scores were achieved by girls from Qatar, United Arab Emirates, and Finland. Looking further into the science plot, we see an unexpected pattern here where most countries have very little gender difference in science scores, implying that most boys and girls perform equally well in science. Boys from Peru, Colombia, and regions of China perform well in science and girls from Qatar, the United Arab Emirates, and Jordan are the top scores for science. Figure \@ref(fig:score-differences) helps us to depict the gender gap in math, reading, and science for all nations and regions that took part in the 2018 PISA experiment.

We gathered meaningful insights about the gender gap between girls and boys across the world from the Figure \@ref(fig:score-differences) because this is a geographical research communication topic, the findings will help us better comprehend the score differences in the three educational disciplines using world maps. Let us continue to investigate and discover patterns and correlations using map visualization. To illustrate the gender gap difference between girls and boys throughout the world, we summarize regions on a country level and utilize the `map_data` function to get the latitude and longitude coordinates needed to construct a map for our data. We connect these latitude and longitude coordinates to our PISA data and render the world map using the `geom_polygon` function wrapped within \CRANpkg{ggplot2} [@ggplot2], the interactive features and placement of the plots are made using \CRANpkg{plotly} [@plotly] and \CRANpkg{patchwork} [@patchwork] packages in R.


```{r}
# Code to match country names between data set
region2country = function(region_name){
  country_name = case_when(
    region_name == "Brunei Darussalam" ~ "Brunei",
    region_name == "United Kingdom" ~ "UK",
    region_name %in% c("Macau SAR China", "B-S-J-Z (China)",
                        "Hong Kong SAR China") ~ "China",
    region_name == "Korea" ~ "South Korea",
    region_name == "North Macedonia" ~ "Macedonia",
    region_name == "Baku (Azerbaijan)" ~ "Baku",
    region_name %in% c("Moscow Region (RUS)", "Tatarstan (RUS)",
                        "Russian Federation") ~ "Russia",
    region_name == "Slovak Republic" ~ "Slovakia",
    region_name == "Chinese Taipei" ~ "Taiwan",
    region_name == "United States" ~ "United States of America",
    region_name == "Serbia" ~ "Republic of Serbia",
    region_name == "Bosnia & Herzegovina" ~ "Bosnia and Herzegovina",
    TRUE ~ as.character(region_name))
}
```

```{r}
# Create the maps of gender difference
math_map_data <- math_diff_conf_intervals  |>
  dplyr::mutate(country_name = region2country(region_name = country_name)) |>
  mutate(test = "math")

read_map_data <- read_diff_conf_intervals |>
  dplyr::mutate(country_name = region2country(region_name = country_name)) |>
  mutate(test = "reading")

sci_map_data <- sci_diff_conf_intervals |>
  dplyr::mutate(country_name = region2country(region_name = country_name)) |>
  mutate(test = "science")

mrs_map_data <- bind_rows(math_map_data, read_map_data, sci_map_data)

world <- ne_countries(scale = "small", 
                      returnclass = "sf") |>
  filter(sovereignt != "Antarctica") 

mrs_world_data <- merge(world, mrs_map_data, 
                         by.x = "sovereignt", 
                         by.y = "country_name", 
                        all = TRUE)

mrs_world_data$diff <- round(mrs_world_data$diff, 2)

mrs_world_data <- rename(mrs_world_data, `f-m` = diff,
                         country = sovereignt)

mrs_world_data_fixed <- mrs_world_data %>%
  filter(!is.na(test)) %>%
  bind_rows(
    mrs_world_data %>% 
      filter(is.na(test)) %>% 
      select(-test) %>% 
      tidyr::crossing(test = c("math", "reading", "science"))) %>% 
  dplyr::filter(st_geometry_type(geometry) != "GEOMETRYCOLLECTION")

mrs_maps <- ggplot(mrs_world_data_fixed) + 
  geom_sf(aes(fill = `f-m`,
              label = country)) +
  facet_wrap(~test, ncol = 1) +
  theme_map() +
  scale_fill_continuous_diverging(palette = "Purple-Green", 
                                  limits = c(-66, 66), 
                                  na.value = "white") +
  theme(panel.border = element_rect(colour = "grey70", fill = NA))
```

```{r plotly-maps, fig.cap="Interactive maps showing the difference in average math, reading, and science scores between girls and boys across the world, positive values (green) indicate the girls average to be higher than boys average, and white indicates a missing value. Mousing over the plots shows the country and score. The average math score is higher for boys in most countries except for some parts of the Middle East, Scandinavia, and Southeast Asia. The average reading score is higher for girls than boys in every country measured.", fig.pos="H", fig.height=12, fig.width=18, out.width="100%", layout="l-body", include=knitr::is_html_output(), eval=knitr::is_html_output(), fig.alt="A set of interactive world maps displaying the difference in average math, reading, and science scores between girls and boys across various countries. The color coding represents the gender difference in scores: green indicates that girls have higher average scores than boys, while purple indicates the opposite. White areas signify missing data. The math score map shows that boys tend to outperform girls in most countries, except in some parts of the Middle East, Scandinavia, and Southeast Asia. The reading score map indicates that girls outperform boys in reading across all measured countries. Hovering over the maps reveals specific country names and score differences."}
interactive_map <- ggplotly(mrs_maps, width = 700, height = 900) %>%
  config(displayModeBar = FALSE)
interactive_map
```

```{r ggplot-maps, fig.cap="Maps showing the gender gap in math, reading, and science results between girls and boys throughout the world. The diverging colour scale makes it possible to interpret the range of scores and it also helps us intrepret the gender gap difference among these students across the globe. The legend displayed enables interpretation of the score differential for each subject across all maps. A positive score for a country indicates that girls outperformed boys in that country, whereas a negative score for a country difference indicates that boys outperformed girls in that country.The reading scores are all positive, suggesting that girls outperform boys globally in the year 2018.", fig.height=9, fig.pos="H", out.width="100%", layout="l-body", include=knitr::is_latex_output(), eval=knitr::is_latex_output()}
mrs_maps
```

In Figure `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(fig:plotly-maps)', '\\@ref(fig:ggplot-maps)'))`, we have shown the gender gap difference between girls and boys in math, reading, and science in 2018. Map visualization aids in the comprehension of large volumes of data in a more efficient manner and increases the ability to compare outcomes across many geographical locations at a glance. Here we can we see both positive and negative score difference scale ranges in all three maps. A positive country score indicates that girls outperformed boys in that country, whereas a negative country score shows that boys outscored girls in that country. The diverging spectral color scale and the legend of these maps makes it possible for us to deduce and identify regions across the globe showing large gender discrepancy between girls and boys. The grey colour for different geographic locations across the maps in Figure `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(fig:plotly-maps)', '\\@ref(fig:ggplot-maps)'))` indicates that these regions were not a part of the PISA experiment in year 2018. Even though the map visualization embeds the same scores as Figure \@ref(fig:score-differences), one of the most striking thing on this map is the lack of data for the Africa continent. We see that there is less of a gender disparity seen in the science scores compared to maths and reading. In addition, the color scale for scores of each subject aids in identifying the countries that took part in the PISA experiment. As a result, in this section, we have seen the gender gap scores and striking trends between 15-year-old girls and boys in math, reading, and science. Our main conclusion from this gender study is the performance of girls in reading. The fewer gender disparity is evident in the science scores, and the majority of boys perform better than girls in mathematics.

# Socioeconomic factors

Socioeconomic status is an economic and sociological complete measure of a person's work experience, economic access to resources, and social standing in relation to others. Do these socioeconomic factors influence students' academic performance? In this section, we will investigate if different socioeconomic factors owned by a family have a significant impact on a student's academic performance. The student dataset in the \CRANpkg{learningtower} package contains scores of 15-year-olds from triennial testing across the world. This dataset also includes information about their parents' education, family wealth, gender, and ownership of computers, internet, cars, books, rooms, desks, and dishwashers. In this section, we will mainly explore some fascinating aspects of the influence of a few socioeconomic factors on student performance in math, reading, and science. Before we go on to our socioeconomic determinants and their impact on students, Figure \@ref(fig:corr-plot) shows how the math, reading, and science scores are strongly positively correlated to one another.

```{r corr-plot, fig.cap ="The hexagon binned pairs plot displays the relationship between math, reading, and science scores for all PISA countries that participated in the experiment in 2018. This scatterplot shows that all three subjects have a significant and positive correlation with each another. The pattern is so regular that it indicates the data is simulated. The documentation confirms this, that the public data is privatised by simulating scores from the fitted model.", fig.width=7.5, fig.pos = "H", out.width="100%", layout="l-body", fig.alt="testing", fig.alt="A set of three hexbin scatter plots visualizing the relationships between math, reading, and science scores. The first plot (left) shows the correlation between math and reading scores, the second (middle) between math and science scores, and the third (right) between reading and science scores. Each plot has a dense central region with lighter shades in the middle, indicating a strong positive correlation between the respective subjects."}
knitr::include_graphics("figures/hexbin.png")
```

We plotted all three scores against each other using the `geom_hex()` function available under the \CRANpkg{ggplot2} [@ggplot2] package in R. The Figure \@ref(fig:corr-plot) help us us reveal the relationship between these three subjects allowing us to deduce that math, science, and reading scores are positively and significantly correlated with one another. This strong correlation structure implies that an analysis between an desired socioeconomic factor and one of the subject scores (e.g. math) should hold similar conclusion if the subject score is replaced with another one (e.g. science). Thus, we decided to show the effect of socioeconomic variables on average math scores in 2018. Let us further explore the impact of a selection of socioeconomic factors on the students' score.

Parents qualification is a vital element of childhood development. As previously stated, the student dataset in the package includes information regarding the parents qualification. In this section, we will investigate if both the mother's and father's qualifications have a significant impact on their child's performance. The mother's education and father's education variables are originally recorded in the student dataset in the \CRANpkg{learningtower} package at distinct International Standard Classification of Education (ISCED) levels which are less than ISCED1 equivalent to ISCED 0, ISCED 1, ISCED 2, ISCED 3A and ISCED 3B, C, where:

-   level 0 indicates pre-primary education or no education at all
-   level 1 indicates primary education or the first stage of basic education
-   level 2 indicates lower secondary education or the second stage of basic education, and
-   level 3 indicates upper secondary education. ISCED level 3 have been further classified into three distinct levels, with ideally very little difference in their classification. This may also be found in the publication [Classifying Educational Programmes](https://www.oecd.org/education/1841854.pdf) [@isced] published by ISCED.

To determine the impact of the parents' qualification we first create data framaes that are categorized by the various countries and regions and grouped by the father's and mother's qualification. We next compute the weighted average of math scores while accounting for student survey weights. Furthermore, we re-factored the parents qualification variable based on the multiple levels of classification, dividing it into four unique levels of education, namely early childhood, primary, lower, and secondary education. Furthermore, we display the weighted math average versus qualification colored by the re factored qualifications levels for both the mother and father using the `geom_quasirandom` function wrapped within \CRANpkg{ggplot2} [@ggplot2], we further plot this with the help of \CRANpkg{viridis} [@viridis] and \CRANpkg{patchwork} [@patchwork] packages in R.

```{r}
load("data/father_qual_math_read_sci_data.rda")
load("data/mother_qual_math_read_sci_data.rda")
mother_qual_math <- ggplot(mother_qual_math_read_sci_data,
       aes(x=`Mother's Education`,
           y=math_avg#,
           )) + #colour=`Mother's Education`)) +
  geom_quasirandom(size = 1.7,
             cex = 3, colour = "grey70") +
  geom_line(aes(group = country_name),
            size=0.5, alpha=.36, colour = "grey70") +
    stat_summary(fun.y = median,
                 fun.ymin = median,
                 fun.ymax = median,
                 geom = "crossbar",
                 width = 0.5,
                 col = "black") +
  theme_bw() +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
    labs(y = "average math score",
         x = "ISCED Level",
         title = "mother")

father_qual_math <- ggplot(father_qual_math_read_sci_data,
       aes(x=`Father's Education`,
           y=math_avg#,
           )) + #colour=`Father's Education`)) +
  geom_quasirandom(size = 1.7,
             cex = 3, colour = "grey70") +
  geom_line(aes(group = country_name),
            size=0.5, alpha=.36, colour = "grey70") +
    stat_summary(fun.y = median,
                 fun.ymin = median,
                 fun.ymax = median,
                 geom = "crossbar",
                 width = 0.5,
                 col = "black") +
  theme_bw() +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
    labs(y = "average math score",
         x = "ISCED Level",
         title = "father")
```

```{r qual-plot, fig.cap ="The impact of parents' education on their children's academic progress, as seen through math scores relative to a parent's highest education level. Each point is the country average, shown as jittered dotplots, and values for each level are connected by lines. The bar corresponds to the median over all countries. There is generally an increase in average math score as parents education is higher. In comparison to parents with lower levels of education qualifications. There is some variation across countries, with some showing decreases in average at the lower education levels, but all show an increase between lower and upper secondary levels.", fig.width = 8, fig.height = 5, fig.pos = "H", out.width="100%", layout="l-body", fig.alt="A pair of scatter plots visualizing the relationship between parents' highest education level (ISCED Level) and their children's average math scores. The left plot represents fathers, and the right plot represents mothers. Each gray dot represents a country's average math score, with points jittered for better visibility. Lines connect data points within each country across different ISCED levels. The thick black horizontal bars indicate the median math score at each education level across all countries. The trend suggests that higher parental education levels correlate with higher average math scores, though there is some variation among countries, particularly at lower education levels."}
father_qual_math + mother_qual_math
```

The Figure \@ref(fig:qual-plot) depicts the impact of mothers' and fathers' qualifications on students academic performance. The Figure \@ref(fig:qual-plot) allows us to deduce a very important and remarkable insight in which we see a constant increase in the students' academic performance when both mother and father qualifications shift towards higher levels of education. The bold horizontal black lines that we see in each category for mother's and father's qualification here represent median score for that qualification category across countries. As the parent attains higher qualifications, we notice an increasing trend in these medians for each category. Taking a closer look at the Figure \@ref(fig:qual-plot), we can see that there is a considerable boost in scores when both the mother and father have upper secondary education. Furthermore, the `geom_quasirandom()` function in the \CRANpkg{ggbeeswarm} [@ggbeeswarm] package makes this plot more accessible and understandable by providing a way to offset points inside categories to prevent overplotting. Thus, we can clearly see that both the mother's and father's qualifications has a significant influence on the student's academic performance, with the more educated the parent more likely to have their child academically performing better.

Television is a common household electronic device for entertainment and news. In this segment of the article, we investigate the influence of television by countries/regions, as well as whether this technology has a significant impact on students' academic performance. The television variables that are recorded in the student dataset is a factor variable that records whether or not the students participating in this study have a television and, if they do, the quantity of televisions per family is recorded via the PISA survey. Furthermore, because we are interested in researching the impact of these television on the students' scores, the television variable initially recorded has four levels: "No TV", "1 TV", "2 TVs", or "3+ TVs". We are also interested in visualising the confidence intervals for each of these levels in order to determine the uncertainty of the results at each level. We begin with initially creating a `data.frame` that is grouped by country and the number of television per household for each country. Next we fit a linear model between the math average and television in the 2018 PISA data and finally plot the television impact for all countries sorted as per the slope with the help of the functions available in the \CRANpkg{ggplot2} [@ggplot2] package.

```{r}
load("data/tv_math_data.rda")

linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}

tv_plot <- tv_math_data |>
  group_by(country_name) |>
  mutate(slope = linear_model(math_avg, television)) |>
  ungroup() |>
  mutate(country_name = fct_reorder(country_name, slope)) |>
  ggplot(aes(x=as.numeric(television), y=math_avg)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
                colour="orange", fill = "orange",
              alpha=0.45) +
  geom_point(size=1.8) +
  geom_line() +
  scale_x_continuous("number of TVs", 
                     labels = levels(tv_math_data$television)) +
  facet_wrap(~country_name, ncol = 8, scales = "free_y") +
  theme_bw() +
  theme(axis.text.x = element_text(vjust = 0.5, hjust=1),
        axis.text.y = element_blank()) +
  ylab("math")
```

```{r tv-plot, fig.cap ="Relationship  between number of TVs in a household and average math scores across countries. Number of TVs ranges from 0 to 3 or more. The orange bands indicate 95 percent standard confidence intervals. The impact of television on student performance is a contentious issue. It is interesting that in some countries for example in Peru and Indonesia the effect appears to be positive, but in other countries like Poland and Germany there is a decline in average math scores.", fig.height=12, fig.width=12, fig.pos = "H", out.width="100%", layout="l-body", fig.alt="A grid of small line charts, each representing a different country, showing the relationship between the number of televisions in a household (ranging from 0 to 3 or more) and average math scores. The x-axis represents the number of TVs, while the y-axis represents average math scores. Each chart contains a black line with data points and an orange band representing the 95% confidence interval. The trends vary across countries: some, like Peru and Indonesia, show an increase in math scores with more TVs, while others, like Poland and Germany, show a decline. This suggests that the effect of television on student performance differs across different countries."}
tv_plot
```

In the Figure \@ref(fig:tv-plot), we can see highly striking patterns as well as a significant influence of television on students' academic performance. We have arranged the nations in the Figure \@ref(fig:tv-plot) according to the slope of math average scores fitted against the different levels of television described previously. Poland, Germany, Slovenia, and Turkey have a lower influence of television on student performance, whereas Malta, Portugal, United Arab Emirates and Qatar have a rising tendency and therefore a larger impact of television on students' performance. Furthermore, the confidence interval plotted in the Figure \@ref(fig:tv-plot) show that there is a lot of uncertainty in the level of scores when a household does not possess a TV in the majority of the countries. Taking a closer look at the Figure \@ref(fig:tv-plot) we observe that when the slope of television increases in countries, the confidence interval of such countries becomes narrower. Hence depending on the wealth and location, television can be a valuable asset since it has a notable effect on a student's academic performance.

It is a common perception that books play an important role in early childhood because they assist learners develop emotional intelligence and creativity. However, the developers of \CRANpkg{learningtower} package intended to investigate if books has a significant influence on the students score. The book variable initially recorded in the student dataset has been categorized in the following levels: "0-10", "11-25", "26-100", "101-200", and "more than 500 books". Doing a similar analysis for books like done for TVs shows that across all the countries the more books in the household the higher the average math score. <!--We will do a similar investigation as we did when we investigated the effect of television. First, we construct a `data.frame` that is grouped by the different levels of books and countries. In addition, we calculated the confidence interval to account for the uncertainty associated with the scores for the different categories of books. We subsequently fit a linear model between the average math score and the book variable to calculate a slope coefficient for each country. Finally, plot the country and score estimations for each country, ordered according to slope with help of the functions available in the \CRANpkg{ggplot2} [@ggplot2] package.-->

```{r eval=FALSE}
z_star_95 <- qnorm(0.975)
load("data/book_math_read_sci_data.rda")
linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}

book_plot <- book_math_read_sci_data |>
  group_by(country_name) |>
  mutate(slope = linear_model(math_avg, book)) |>
  ungroup() |>
  mutate(country_name = fct_reorder(country_name, slope)) |>
  ggplot(aes(x=as.numeric(book), y=math_avg)) +
  geom_ribbon(aes(ymin = bk_lower, ymax = bk_upper),
                colour="orange", fill="orange", alpha=0.45) +
  geom_point(size=1.8) +
  geom_line(aes(group = country_name)) +
  facet_wrap(~country_name, ncol = 8, scales = "free") +
  theme(axis.text = element_blank()) +
  labs(x = "Number of Books",
       y = "Average Mathematics Score")
```

```{r book-plot, fig.cap ="Impact of the number of books on average math score. Number of books ranges from 0 to 500 and more. 95 percent standard confidence bands shown in orange. Math scores generally increase as the number of books increases. Averages for some countries at the higher number of books are less reliable, and hence the decline reflects more that there are few households with this many books than a true decline.", fig.height=12, fig.width=12, fig.pos = "H", out.width="100%", layout="l-body", eval=FALSE}
book_plot
```

There are other household resource variables in the sample of PISA data, including internet, computer access, room of their own, desk access, even whether the household has a dishwasher, that can be examined in relation to test scores.

# Temporal trend

In this section of analysis, we look at the temporal trends noticed in Australia. The release of PISA results in 2018 led to several headlines on the decline in scores recorded in Australia. In this section, we will determine whether this decrease is indeed significant or whether there are any other aspects to consider when comparing country rankings. To better comprehend Australia's scores and trends since 2000, the developers of the \CRANpkg{learningtower} package, feel it is appropriate to illustrate the temporal trend of Australia in comparison to a few other nations. We evaluate these countries performance using a statistical procedure bootstrapping using the `map_dfr` function which re-samples a single dataset to generate a large number of simulated samples. We will compare the results of these bootstrap samples across all the years they participated in PISA and highlight a few countries with help of \CRANpkg{gghighlight} [@gghighlight] performance to compare with Australia's

```{r bs-plot, fig.cap ="Temporal patterns in math, reading, and science in a variety of countries. The highlighted countries in the chart help us infer Australia's performance in contrast to the other countries; we can see that Australia's scores have always been among the highest in the PISA survey throughout all years.", fig.height=10, fig.width=10, fig.pos = "H", out.width="100%", layout="l-body", fig.alt=" A set of three line charts showing temporal trends in math, reading, and science scores across multiple countries from the early 2000s to 2020. Each panel represents a different subject, with individual country trends shown in faint gray lines, while selected countries, including Singapore, Canada, Australia, Denmark, Greece, Qatar, Thailand, Peru, and Brazil, are highlighted in bold black lines with labels. The chart indicates that Australia's performance has consistently remained among the highest in the PISA survey across all years, while other countries show varying trends of improvement or decline in scores."}
load("data/all_bs_cf.rda")

all_bs_cf <- all_bs_cf |>
  mutate(year = as.numeric(as.character(year)),
         country_name = factor(country_name))
                  #levels = c("Singapore",
                  #         "Australia",
                  #         "New Zealand",
                  #         "Germany",
                  #         "Qatar",
                  #         "Indonesia"))


country_names_highlight <- c("Australia", 
                             "Peru", 
                             "Qatar", 
                             "Brazil", 
                             "Denmark", 
                             "Greece",
                             "Thailand", 
                             "Singapore", 
                             "Canada")

keep <- all_bs_cf |>
  count(country_name) |>
  filter(n > 12) |>
  pull(country_name) 
  
all_bs_cf_sub <- all_bs_cf |>
  filter(country_name %in% keep)

math_all_bs_cf_plot <- all_bs_cf_sub |> 
  dplyr::filter(subject == "math") |> 
  ggplot(aes(x = year, 
      y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight,
                           label_params = list(fill = NA)) +
  labs(
    title = "math",
     x = "",
     y = "score") +
  theme_bw()


read_all_bs_cf_plot <- all_bs_cf |> 
  dplyr::filter(subject == "read") |> 
  ggplot(aes(x = year, 
      y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight,
                           label_params = list(fill = NA)) +
  labs(
    title = "reading",
     x = "",
     y = "score") +
  theme_bw()

sci_all_bs_cf_plot <- all_bs_cf |> 
  dplyr::filter(subject == "science") |> 
  ggplot(aes(x = year, 
      y = avg)) +
  geom_point(alpha = 0.45) +
  geom_line(aes(group = country_name)) +
  gghighlight::gghighlight(country_name %in% country_names_highlight,
                           label_params = list(fill = NA)) +
  labs(
    title = "science",
     x = "",
     y = "score") +
  theme_bw()


math_all_bs_cf_plot + read_all_bs_cf_plot + sci_all_bs_cf_plot

```

Taking a deeper look at the Figure \@ref(fig:bs-plot) and comparing Australia's scores to a few of the selected countries, we notice the changing scales of their scores in all three plots of math, reading, and science and we infer that Australia's performance has been is much better than than majority of the countries. To deepen our understanding of the topic, we compare Indonesia's, Qatar's or Peru's results to those of Australia and observe and increasing pattern for all of them but Australia. On closer examination we witness that the highest score for Indonesia, Qatar or Peru are initially low scores and this increases further. However, Australia's performance in the PISA was initially a top achievement, and it has only drops by a few points. Though the temporal trend of Australia displays a declining tendency, this is due to the fact that Australia initially performed very well in the PISA experiment and has only decreased it scores by a few points each year, remaining in one of the top scores of the PISA research until the year 2018. As a result, we infer that Australian's performance has declined over time but the country has remained on the list of top scores countries for all of the years this PISA research has been done. Using a similar notion, we conclude that countries with lower initial PISA results have a tendency to increase their score each time the PISA exam is taken whilst countries that have previously established a standard with great score results like Australia may witness a decreasing trend in the scores but optimally the scores has decrease by a few points only thus not making the the declining trend a significant measure of performance. In addition, to understand this better, we have a animation plotted using \CRANpkg{gganimate} [@gganimate] the that explains how performance can only be compared among scales and not based on scores or any other characteristics with respect to several other countries that participated in the PISA experiment.

```{r facet-time, fig.cap = "Math and reading scores over time, with selected countries labelled. Colour indicates continent. Australia has quite stable scores over the years.", eval = TRUE, fig.width = 9, fig.height = 6, out.width="100%", layout="l-body-outset", fig.alt="A series of eight scatter plots arranged in a 2x4 grid, each representing different years (2000, 2003, 2006, 2009, 2012, 2015, 2018, and 2022). The x-axis represents math scores, and the y-axis represents reading scores from the PISA survey. Each point represents a country, colored by continent. Some countries, including Australia, Finland, Canada, Singapore, the USA, Brazil, Thailand, Indonesia, and Qatar, are labeled. Australia, consistently positioned among the top-performing countries, is highlighted. The overall trend shows a strong positive correlation between math and reading scores across all years."}
load("data/student_anim_data.rda")
ggplot(student_anim_data,
       aes(x=math_avg, y=read_avg,
           color = continent)) +
  geom_point(size=2, alpha=0.5) +
  geom_text_repel(data = filter(student_anim_data,
                          country_name %in%
                            c("Australia", 
                              #"New Zealand",
                              "Indonesia", 
                              "Qatar",
                              "Singapore",
                              #"Germany",
                              "Malaysia",
                              "Finland",
                              "Canada",
                              #"Germany",
                              "Thailand",
                              "Brazil",
                              #"Colombia",
                              #"Chile",
                              "USA")), 
            aes(label = country_name), size=2, 
            max.overlaps = 20) +
  theme_bw() +
  theme(legend.position = "bottom", 
        aspect.ratio=1) +
  facet_wrap(~year, ncol=4) +
  scale_colour_brewer("", palette = "Dark2") +
  labs(x = "math",
       y = "reading")
```

# Discussion

In this R Journal article, we introduce the R package \CRANpkg{learningtower}, which provides a subset of variables from the OECD's PISA survey, which is undertaken every three years. This is an excellent dataset that may be utilised for a variety of analyses and advanced statistical computations. The package contains three datasets: student, school and countrycode this provides us with information about the students scores in mathematics, reading and science. The student dataset comprises of the scores from the triennial testing of 15-year-olds worldwide. Keeping in mind the package's size constraints. The package only includes a portion of student data, called the student subset data, this subset of student data is available for all the years when the PISA experiment took place. The full year wise student dataset can be downloaded using the `load_student()` function included in this package. In addition the school and countrycode dataset available in the package describe the characteristics of schools these children attended and the countrycode dataset contains mapping of the country ISO code to the country name respectively. Furthermore, detailed information of the \CRANpkg{learningtower} package can be available in the [articles](https://kevinwang09.github.io/learningtower/articles/learningtower_school.html) section of the package website that offers information on how to load and use these datasets.

Conducting research and analysis provides insight into what the researchers have gathered from the complete set of data. In this article, we see several examples of analysis and answers to a few research questions. These analysis can serve as a solid foundation for a variety of academics and researchers that wish to do research on the PISA data. In this paper we analysed the gender gap difference in 15-year-olds' in math, reading, and science outcomes in 2018 and discovered several unique and remarkable trends. Furthermore, the world maps plotted aided us better comprehend and determining the gender gap scores. We also demonstrate how the three scores of math, reading, and science were highly and positively correlated with one another and investigate the influence of various socioeconomic conditions on students' academic performance we witness the impact of factors such as father qualifications, mother qualifications, the number of televisions a household owns, the number of books a household possess, and access to computer and internet that show us remarkable insights on the students' results. Moreover, we delve into the history of Australia's score and examine the temporal pattern of the scores of a few selected countries, as well as witness Australia's top achievement in the PISA study across all years.

# Acknowledgments

This paper is written using the [rjtools](https://github.com/rjournal/rjtools) [@rjtools] package, which depends on Rmarkdown [@rmarkdown]. The work depends on the many contributors to the \CRANpkg{learningtower} package. Two Master of Business Analytics students at Monash University, Shabarish Sai Subramanian and Guan Ru Chen compiled the 2022 PISA data, and updated the package. These final RDS file for each PISA year were then thoroughly vetted and made available in a separate [GitHub repository](https://github.com/kevinwang09/learningtower_masonry).
